{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hardik Prabhu-NlpAssignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3kdsz6aC5hSoJ/0/GHoSZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HardikPrabhu/Natural-Language-Processing-on-the-Covid-19-Research-papers/blob/main/Hardik_Prabhu_NlpAssignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyloMGzPz6cl"
      },
      "source": [
        "Hardik Prabhu\n",
        "\n",
        "Roll Number: MDS201912"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9YErfWYtqsS"
      },
      "source": [
        "**Picking up from where we left...**\n",
        "\n",
        "In the previous notebook, we preprocessed the json corpus such that each of the document got converted into bag of bag of words (list of list). We also decided on retaining the stopwords as it will help us to make a better n-gram model, which would  mimic the syntatical struture of the sentences. This lead to blow up of the memory usage and we had to resort to partitioning of the corpus into 16 parts. Each partion was preprocessed seperatly and then after preprocessing, each stored as a pickle objects along with their respective vocabularies (list of words).\n",
        "\n",
        "We will use the preprocesssed corpus to create n-gram models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYYFValxxsqe"
      },
      "source": [
        "**Fetching the pickle objects**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGWLaT1fyYHG",
        "outputId": "9cd337c1-a049-4d7b-8010-2ed7d0658272"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PhzBwkuxEFu"
      },
      "source": [
        "import os\n",
        "location=\"/content/drive/MyDrive/pdf_json\"  #location of json files\n",
        "save_location=\"/content/drive/MyDrive\"      #location on my gdrive\n",
        "os.chdir(save_location)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnhXmiguyxv1"
      },
      "source": [
        "Getting the vocabulary.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp18sl97zQrA"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xImgLqpTywpL",
        "outputId": "1e8b5768-22b0-4f72-9548-e2c47c342d0a"
      },
      "source": [
        "vocabulary=set()  #entire vocabulary by taking the union over the partitons. \n",
        "os.chdir(save_location)\n",
        "for m in range(16):\n",
        "  with open(\"vocab-\"+str(m), \"rb\") as f:\n",
        "    \n",
        "     vocab=pickle.load(f)\n",
        "         \n",
        "     \n",
        "  vocabulary=vocabulary.union(vocab)\n",
        "\n",
        "print(\"Vocabulary size: \"+ str(len(vocabulary)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 801851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnxAxnbJZ5TY"
      },
      "source": [
        "**Converting into n-tuples**\n",
        "\n",
        "The sentences(list of words) are processed further to get a collection of n-tuples which are required for creation of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBgclpBV0VPw"
      },
      "source": [
        "#tuple extraction\n",
        "from nltk.util import ngrams\n",
        "def n_tuple_extract(Corpus,n):\n",
        "  c=[]\n",
        "  for doc in Corpus:\n",
        "    for sentence in doc:\n",
        "      x=list(ngrams(sentence,n, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n",
        "      c=c+x\n",
        "  return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87Oz4lTFnwOC"
      },
      "source": [
        "**Tri-gram model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYA2Xi5CbQMg",
        "outputId": "79fed37d-6ac5-4230-c0cb-f0b04c39e694"
      },
      "source": [
        "#example\n",
        "corp=[[[\"this\", \"is\", \"a\", \"sentence\"],[\"another\", \"sentence\", \"in\",\"the\",\"same\", \"document\"]],[[\"a\",\"sentence\", \"in\",\"different\",\"document\"],[\"this\",\"is\",\"a\",\"short\",\"document\"]]]\n",
        "print(n_tuple_extract(corp,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<s>', '<s>', 'this'), ('<s>', 'this', 'is'), ('this', 'is', 'a'), ('is', 'a', 'sentence'), ('a', 'sentence', '</s>'), ('sentence', '</s>', '</s>'), ('<s>', '<s>', 'another'), ('<s>', 'another', 'sentence'), ('another', 'sentence', 'in'), ('sentence', 'in', 'the'), ('in', 'the', 'same'), ('the', 'same', 'document'), ('same', 'document', '</s>'), ('document', '</s>', '</s>'), ('<s>', '<s>', 'a'), ('<s>', 'a', 'sentence'), ('a', 'sentence', 'in'), ('sentence', 'in', 'different'), ('in', 'different', 'document'), ('different', 'document', '</s>'), ('document', '</s>', '</s>'), ('<s>', '<s>', 'this'), ('<s>', 'this', 'is'), ('this', 'is', 'a'), ('is', 'a', 'short'), ('a', 'short', 'document'), ('short', 'document', '</s>'), ('document', '</s>', '</s>')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpKcohglnnaJ"
      },
      "source": [
        "We maintain a dictionary of counts in order to generate probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opZwHgfUnly4"
      },
      "source": [
        "\n",
        "def counting(c,counts):\n",
        " \n",
        " for i in c:\n",
        "    if (i[:-1],i[-1]) in counts:\n",
        "        counts[i[:-1],i[-1]]=counts[i[:-1],i[-1]]+1\n",
        "    else:\n",
        "        counts[i[:-1], i[-1]]=1\n",
        " return counts                        \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVv7foPtrGvG",
        "outputId": "f48fdef8-c3c7-4418-896b-d0cc813769fc"
      },
      "source": [
        "counts={}\n",
        "counting(n_tuple_extract(corp,3),counts)\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{(('<s>', '<s>'), 'this'): 2, (('<s>', 'this'), 'is'): 2, (('this', 'is'), 'a'): 2, (('is', 'a'), 'sentence'): 1, (('a', 'sentence'), '</s>'): 1, (('sentence', '</s>'), '</s>'): 1, (('<s>', '<s>'), 'another'): 1, (('<s>', 'another'), 'sentence'): 1, (('another', 'sentence'), 'in'): 1, (('sentence', 'in'), 'the'): 1, (('in', 'the'), 'same'): 1, (('the', 'same'), 'document'): 1, (('same', 'document'), '</s>'): 1, (('document', '</s>'), '</s>'): 3, (('<s>', '<s>'), 'a'): 1, (('<s>', 'a'), 'sentence'): 1, (('a', 'sentence'), 'in'): 1, (('sentence', 'in'), 'different'): 1, (('in', 'different'), 'document'): 1, (('different', 'document'), '</s>'): 1, (('is', 'a'), 'short'): 1, (('a', 'short'), 'document'): 1, (('short', 'document'), '</s>'): 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LsliBiIroHh"
      },
      "source": [
        "We argue that maintaing such a dictionary will yield sufficient information to generate probabilities.\n",
        "Hence, once counts are generated, the tuples can be thrown away to save ram blow up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "CEILZRqSeJcX",
        "outputId": "a5f72727-a9c2-4a2a-8d74-a9349e656e46"
      },
      "source": [
        "counts={}\n",
        "for m in range(15):\n",
        "  \n",
        "  with open(\"nlp-\"+str(m), \"rb\") as f:\n",
        "    corp=pickle.load(f)\n",
        "    print(\"corpus\"+str(m)+\" loaded\")\n",
        "  x=n_tuple_extract(corp,3)\n",
        "  print(\"trigrams created\")\n",
        "  counting(x,counts)\n",
        "  x=[]\n",
        "  print(\"partion done\") \n",
        "\n",
        "with open(\"trigram counts-1\",\"wb\") as f: #save it for later\n",
        "  pickle.dump(counts,f)\n",
        "\n",
        "\n",
        "\n",
        "                              \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus0 loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3ce739103dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"corpus\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_tuple_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trigrams created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mcounting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2444bce9aaa6>\u001b[0m in \u001b[0;36mn_tuple_extract\u001b[0;34m(Corpus, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_left\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_right\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_pad_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<s>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_pad_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'</s>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFr7JAv2Viig"
      },
      "source": [
        "I have been struggling for weeks to resolve the memory blow up. The above stategy of dividing into 16 parts failed  as well. Google allows only 15 gb storage max and 12 gb ram. Its not enough to work with the entire corpus.\n",
        "A lot of efforts into approaching part by  part has resulted in a lot of runtime error. I will be working on a seperate colab notebook. Please accept the submission done on the smaller portion of the data. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzKDs0IX2PjL"
      },
      "source": [
        "I will use a small section (1000 documents) of the entire corpus for trainning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-5jiqse2O2J"
      },
      "source": [
        "with open(\"nlp-1\", \"rb\") as f:\n",
        "    corp=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9RZ_kjoa8y3"
      },
      "source": [
        "with open(\"vocab-1\",\"rb\") as f: #vocabulary for the section of corpus\n",
        "  vocab=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Z-51AX5-nK"
      },
      "source": [
        "test=corp[1000:1004] #for evaluationg the model later\n",
        "corp=corp[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHqqHGfd6Fys",
        "outputId": "e110f0ff-ebf6-4103-b758-029f82306273"
      },
      "source": [
        "counts={}\n",
        "x=n_tuple_extract(corp,3)\n",
        "print(\"trigrams created\")\n",
        "counting(x,counts)\n",
        "\n",
        "with open(\"trigram counts\",\"wb\") as f: #save it for later\n",
        "  pickle.dump(counts,f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trigrams created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHkWXxRg7Eap",
        "outputId": "e8cd041e-4484-4710-b740-8a7e446e28e2"
      },
      "source": [
        "with open(\"trigram counts\",\"rb\") as f: \n",
        "  counts=pickle.load(f)\n",
        "\n",
        "len(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2472276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJoTC7Fhbhjf"
      },
      "source": [
        "#generating probabilities\n",
        "def prob(x):\n",
        "    total=0\n",
        "    z=0\n",
        "    if (x[:-1],x[-1]) in counts:\n",
        "     z=counts[x[:-1],x[-1]]\n",
        "\n",
        "     for y in counts:\n",
        "        if y[0]==x[:-1]:\n",
        "            total=total+counts[y]\n",
        "\n",
        "     return z/total\n",
        "    else:\n",
        "        return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V2lLlsYehXW",
        "outputId": "077021d5-bcd5-46fd-d590-1732e21d25de"
      },
      "source": [
        "#generating probability for p(serious| poses a):\n",
        "prob(('poses', 'a', 'serious'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1111111111111111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM6XTCI5fLK1"
      },
      "source": [
        "We will use the function prob to generate a random sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrJyp87pe5U7"
      },
      "source": [
        "import numpy\n",
        "def generate(s):\n",
        "    y=s.split()\n",
        "    probability=[]\n",
        "    words=[]\n",
        "    for v in vocab:\n",
        "      z=prob(tuple(y[-2:]+[v]))\n",
        "      if z!=0:\n",
        "         probability.append(z)\n",
        "         words.append(v)\n",
        "    try:\n",
        "     word= numpy.random.choice(numpy.arange(0, len(words)), p=probability)\n",
        "     s=s+\" \"+ words[word]\n",
        "    except: #due to some numeric error probabilities may not sum up to 1 (valueerror)\n",
        "        p=1-sum(probability)\n",
        "        words.append(\"</s> </s> <s> <s>\")\n",
        "        probability.append(p)\n",
        "        word = numpy.random.choice(numpy.arange(0, len(words)), p=probability)\n",
        "        s = s + \" \" + words[word]\n",
        "\n",
        "    return s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR8iOjzofpiB"
      },
      "source": [
        "We have created a function which would given a string as an input will generate a new word and add it at the end and return the string. \n",
        "\n",
        "The function simply looks at the last 2 words (w1,w2) in the string and for any word w in the vocabulary calculates p(w| w1, w2) using the prob fuction which was defined earlier. We maintain a list on words with non-zero probability and a list of respective probabilities and use the probabilities to sample a word from the list.   \n",
        "\n",
        "Ideally we would like to see the sum of the probabilities to be 1 over the entire vocabulary. But since we are adding a large number of small floating point numbers, they may not add up to 1 and a value error might be thrown.\n",
        "To tackle this we give remaing probability to the seq $</s> </s> <s> <s>$  indicating end of the old sentence and beginning of a new one. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3o-JsI7j99g",
        "outputId": "e9a7057d-0abd-4b1f-aaa6-dee3cf03fe06"
      },
      "source": [
        "#creating a 20 words string using trigarm model\n",
        "s=\"<s> <s>\"\n",
        "for i in range(20):\n",
        "  s=generate(s)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> <s> negative interruptions are one of the role of ezrin in hepatocytes c regulates the transport sector is weak eg social\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WKvSaZ4Y_By"
      },
      "source": [
        "# most occuring starting word\n",
        "max=0\n",
        "word=\"\"\n",
        "for j in vocab:\n",
        "  try:\n",
        "   c=counts[(\"<s>\",\"<s>\"),j]\n",
        "   if c>max:\n",
        "    max=c\n",
        "    word=j\n",
        "  except:\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_6jXDTYdKu8",
        "outputId": "386ecd2d-db2b-4c87-d214-2a14f4f04f68"
      },
      "source": [
        "print (word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vjd1ZG6doBk"
      },
      "source": [
        "The word with max occurence at the beginning is: \"the\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V6o6sm5fM0a",
        "outputId": "9e8cf307-62e0-496d-b354-f28e24458528"
      },
      "source": [
        "s=\"<s> the\"\n",
        "for i in range(25):\n",
        "  s=generate(s)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> the role of host factors such as ssagwtagaa of microbacteria cover match or outperform other outcome predictors such as temperature conductivity and s in ii and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NjclcOMYl9D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDxNoUwtwibq"
      },
      "source": [
        "**The 4-gram model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk7135pLw8Sv",
        "outputId": "8f129650-7e63-4cc5-f25b-49841986ca01"
      },
      "source": [
        "#example \n",
        "c=[[[\"this\", \"is\", \"a\", \"sentence\"],[\"another\", \"sentence\", \"in\",\"the\",\"same\", \"document\"]],[[\"a\",\"sentence\", \"in\",\"different\",\"document\"],[\"this\",\"is\",\"a\",\"short\",\"document\"]]]\n",
        "print(n_tuple_extract(c,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<s>', '<s>', '<s>', 'this'), ('<s>', '<s>', 'this', 'is'), ('<s>', 'this', 'is', 'a'), ('this', 'is', 'a', 'sentence'), ('is', 'a', 'sentence', '</s>'), ('a', 'sentence', '</s>', '</s>'), ('sentence', '</s>', '</s>', '</s>'), ('<s>', '<s>', '<s>', 'another'), ('<s>', '<s>', 'another', 'sentence'), ('<s>', 'another', 'sentence', 'in'), ('another', 'sentence', 'in', 'the'), ('sentence', 'in', 'the', 'same'), ('in', 'the', 'same', 'document'), ('the', 'same', 'document', '</s>'), ('same', 'document', '</s>', '</s>'), ('document', '</s>', '</s>', '</s>'), ('<s>', '<s>', '<s>', 'a'), ('<s>', '<s>', 'a', 'sentence'), ('<s>', 'a', 'sentence', 'in'), ('a', 'sentence', 'in', 'different'), ('sentence', 'in', 'different', 'document'), ('in', 'different', 'document', '</s>'), ('different', 'document', '</s>', '</s>'), ('document', '</s>', '</s>', '</s>'), ('<s>', '<s>', '<s>', 'this'), ('<s>', '<s>', 'this', 'is'), ('<s>', 'this', 'is', 'a'), ('this', 'is', 'a', 'short'), ('is', 'a', 'short', 'document'), ('a', 'short', 'document', '</s>'), ('short', 'document', '</s>', '</s>'), ('document', '</s>', '</s>', '</s>')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU4xVC1X04D6"
      },
      "source": [
        "Using the same counting fuction as before to generate a dictionary of counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLbXAE1SyQbN",
        "outputId": "0c78f3b2-f79b-4552-9e40-a229f1d93923"
      },
      "source": [
        "counts4={}\n",
        "counting(n_tuple_extract(c,4),counts4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(('<s>', '<s>', '<s>'), 'a'): 1,\n",
              " (('<s>', '<s>', '<s>'), 'another'): 1,\n",
              " (('<s>', '<s>', '<s>'), 'this'): 2,\n",
              " (('<s>', '<s>', 'a'), 'sentence'): 1,\n",
              " (('<s>', '<s>', 'another'), 'sentence'): 1,\n",
              " (('<s>', '<s>', 'this'), 'is'): 2,\n",
              " (('<s>', 'a', 'sentence'), 'in'): 1,\n",
              " (('<s>', 'another', 'sentence'), 'in'): 1,\n",
              " (('<s>', 'this', 'is'), 'a'): 2,\n",
              " (('a', 'sentence', '</s>'), '</s>'): 1,\n",
              " (('a', 'sentence', 'in'), 'different'): 1,\n",
              " (('a', 'short', 'document'), '</s>'): 1,\n",
              " (('another', 'sentence', 'in'), 'the'): 1,\n",
              " (('different', 'document', '</s>'), '</s>'): 1,\n",
              " (('document', '</s>', '</s>'), '</s>'): 3,\n",
              " (('in', 'different', 'document'), '</s>'): 1,\n",
              " (('in', 'the', 'same'), 'document'): 1,\n",
              " (('is', 'a', 'sentence'), '</s>'): 1,\n",
              " (('is', 'a', 'short'), 'document'): 1,\n",
              " (('same', 'document', '</s>'), '</s>'): 1,\n",
              " (('sentence', '</s>', '</s>'), '</s>'): 1,\n",
              " (('sentence', 'in', 'different'), 'document'): 1,\n",
              " (('sentence', 'in', 'the'), 'same'): 1,\n",
              " (('short', 'document', '</s>'), '</s>'): 1,\n",
              " (('the', 'same', 'document'), '</s>'): 1,\n",
              " (('this', 'is', 'a'), 'sentence'): 1,\n",
              " (('this', 'is', 'a'), 'short'): 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMylmDpS1FcT",
        "outputId": "f8466710-5760-46a6-a650-925f6ecb95e4"
      },
      "source": [
        "counts4={}\n",
        "x=n_tuple_extract(corp,4)\n",
        "print(\"4-grams created\")\n",
        "counting(x,counts4)\n",
        "\n",
        "with open(\"4-gram counts\",\"wb\") as f: #save it for later\n",
        "  pickle.dump(counts4,f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4-grams created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9N2PggkzMGg"
      },
      "source": [
        "with open(\"4-gram counts\",\"rb\") as f: \n",
        "  counts4=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kECCkcMfTTuT",
        "outputId": "0591b186-d93d-47c0-c8a5-4837317035d7"
      },
      "source": [
        "len(counts4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3262901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hh53za5To7o"
      },
      "source": [
        "def prob4(x):\n",
        "    total=0\n",
        "    z=0\n",
        "    if (x[:-1],x[-1]) in counts4:\n",
        "     z=counts4[x[:-1],x[-1]]\n",
        "\n",
        "     for y in counts4:\n",
        "        if y[0]==x[:-1]:\n",
        "            total=total+counts4[y]\n",
        "\n",
        "     return z/total\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB_bzz8FUEgJ",
        "outputId": "227a4b92-90d0-4635-8b1b-1934a2a7b1d1"
      },
      "source": [
        "#example\n",
        "prob4((\"<s>\",\"<s>\",\"<s>\",\"the\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13517611219519043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg0sqVknVOmL"
      },
      "source": [
        "def generate4(s):\n",
        "    y=s.split()\n",
        "    probability=[]\n",
        "    words=[]\n",
        "    for v in vocab:\n",
        "      z=prob4(tuple(y[-3:]+[v]))\n",
        "      if z!=0:\n",
        "         probability.append(z)\n",
        "         words.append(v)\n",
        "    try:\n",
        "     word= numpy.random.choice(numpy.arange(0, len(words)), p=probability)\n",
        "     s=s+\" \"+ words[word]\n",
        "    except: #due to some numeric error probabilities may not sum up to 1 (valueerror)\n",
        "        p=1-sum(probability)\n",
        "        words.append(\"</s> </s> </s> <s> <s> <s>\")\n",
        "        probability.append(p)\n",
        "        word = numpy.random.choice(numpy.arange(0, len(words)), p=probability)\n",
        "        s = s + \" \" + words[word]\n",
        "\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhRQaNzYVtdL"
      },
      "source": [
        "#the starting word with maximal occurence\n",
        "max=0\n",
        "word=\"\"\n",
        "for j in vocab:\n",
        "  try:\n",
        "   c=counts4[(\"<s>\",\"<s>\",\"<s>\"),j]\n",
        "   if c>max:\n",
        "    max=c\n",
        "    word=j\n",
        "  except:\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSp0A2RWneDn",
        "outputId": "af47665b-1e90-4eba-e757-5647bca79881"
      },
      "source": [
        "print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYTiesOEVjYU",
        "outputId": "95e4df4a-a5db-408e-d600-3663e74a57f7"
      },
      "source": [
        "s=\"<s> <s> the\"\n",
        "for i in range(25):\n",
        "  s=generate4(s)\n",
        "\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> <s> the pharmaceutical in nanjangud is in the process of enhancing hot cognitions by discussing food intake just before weighing to enhance excessive weight predictions and consequent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG6xUSSVagqe"
      },
      "source": [
        "**Comparing the two models:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2E4aDg0_oTp"
      },
      "source": [
        "We will evaluate our language models by comparing log of perplexity obtained over a test dataset. Perpelxity is a measure of fit, lower the better. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8AA_lnPa0DU"
      },
      "source": [
        "def log_perplexity_trigram(trigrams,eps): #small amount eps is added to handle when prob(tuple) is zero \n",
        "     perp=0\n",
        "     for tuple in trigrams:\n",
        "         perp=perp+numpy.log(prob(tuple)+eps)  #applying the chain rule p(w1,w2,w3,..wn)=p(w1,w2)p(w3|w2,w1)...p(wn|wn-1,wn-2)\n",
        "     #p(w1,w2) i.e p(<s> <s>): counts of trigrams statring with <s> <s> / total number of trigrams in tranning corpus\n",
        "     total=0\n",
        "     count=0\n",
        "     for j in counts:\n",
        "         total=total +counts[j]\n",
        "         if j[0]==(\"<s>\",\"<s>\"):\n",
        "             count=count+counts[j]\n",
        "     p=count/total\n",
        "     perp=perp+numpy.log(p)\n",
        "     perp=-1*perp/len(trigrams)\n",
        "     return perp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfEnkCGwxY_f"
      },
      "source": [
        "def log_perplexity_4gram(fgrams,eps):\n",
        "     perp=0\n",
        "     for tuple in fgrams:\n",
        "         perp=perp+numpy.log(prob4(tuple)+eps)  #applying the chain rule p(w1,w2,w3,..wn)=p(w1,w2, w3)p(w4|w3,w2,w1)...p(wn|wn-1,wn-2,wn-3)\n",
        "     #p(w1,w2,w3) i.e p(<s> <s> <s>): counts of 4-grams statring with <s> <s> <s> / total number of 4-grams in tranning corpus\n",
        "     total=0\n",
        "     count=0\n",
        "     for j in counts4:\n",
        "         total=total +counts4[j]\n",
        "         if j[0]==(\"<s>\",\"<s>\",\"s\"):\n",
        "             count=count+counts4[j]\n",
        "     p=count/total\n",
        "     perp=perp+numpy.log(p)\n",
        "     perp=-1*perp/len(fgrams)\n",
        "     return perp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh5D17Iu_9WQ"
      },
      "source": [
        "test1=n_tuple_extract(test,3)\n",
        "test2=n_tuple_extract(test,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e2I_VcaHAKj",
        "outputId": "607dde0a-a787-4e28-c7ba-15cd96431984"
      },
      "source": [
        "#perplexity calculations over the test corpus\n",
        "print(\"The trigram model\")\n",
        "print(log_perplexity_trigram(test1,0.000001))\n",
        "print(\"The 4-gram model\")\n",
        "print(log_perplexity_4gram(test2,0.000001))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The trigram model\n",
            "10.506219706915168\n",
            "The 4-gram model\n",
            "12.230797815587836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiCq9F6-ieeW"
      },
      "source": [
        "It seems that the tri-gram model is fitting better than the 4-gram model on the test corpus. (has a lower log perplexity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOwsFyckDio"
      },
      "source": [
        "Q.6. Ans: The only model parameters are the dictionaries of counts. we use the dictionaries to generate probablities. To handle a large dictionary, we can maintain multiple small dictionaries instead of a large one and can sweep across them in parallel  and add up the counts while generating probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Oc4zIJm93u"
      },
      "source": [
        "Q.7   Ans: We can partition the corpus and then on each partition create n-grams parallelly. We can maintain separate dictionaries of counts for each of the partitions and then add up the counts from each partition while generating probabilities.  "
      ]
    }
  ]
}